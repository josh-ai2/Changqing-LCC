{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Files inside Logs\n",
    "\n",
    "## Time_series_modelling_+_feature_extraction_+_transformer.ipynb\n",
    "\n",
    "The transformer method is still a work in progress. It was successful in compressing the entire dataset by 100%. So each raw time series data went from 750k+ rows to 75k+ rows. However, the only issue is that this decreases the accuracy, as I have not found a classifer that works well in interpreting the features that the transformer condensed.\n",
    "\n",
    "We also attempt to use Deep Embedded Clustering (called DEC) to cluster the compressed time series data into 5 clusters WITHOUT SUPERVISION. The 5 clusters were decided by the model, yet cross-checking this with groundtruth, we get mixed results. Sometimes, two classes of trees belonging to one cluster.\n",
    "\n",
    "For instance, the model classifies a set of points under cluster 1, yet cross-checking these points with groundtruth, we get larch_CN and shrubland both belonging to cluster 1. The results from DEC are not satisfactory, indicating that by running a transformer to compress the data, we are decreasing the \"distinctiveness\" of each tree species class with one another.\n",
    "\n",
    "That is my critique of using transformers to encode and compress time series data. Regardless, if you want to see the process of going through and testing everything, go to the original time_series_modelling ipynb file in logs directory\n",
    "\n",
    "\n",
    "## Groundtruth_analysis.ipynb\n",
    "\n",
    "This piece of code focuses mainly on LSTM approach (semi-supervised). The code there works and most of the code here in main workflow is inspired from groundtruth analysis code located in logs."
   ],
   "id": "bfe07f09a71b1c18"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## What's inside this code?\n",
    "### This is the main pipeline that works. Components:\n",
    "1. GEE time series sampler code -- exports it into Google Drive, check task manager\n",
    "2. CSV cleaner -- remove the .geo coordinate and run regex to extract lat long, also implement a CSV summarizer.\n",
    "3. LSTM model; classifed on unseen data"
   ],
   "id": "4ad22e110eded8ee"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## (1) Time-Series Sampler (written in Javascript, execute in GEE)\n",
    "\n",
    "1. Define a study area polygon, compute its centroid, and adjust dimensions (m to degrees) for grid alignment.\n",
    "2. Generate a grid of 256×256 patches by converting patch size (2560 m) to degrees.\n",
    "3. Filter and process Sentinel-2 images (cloud masking, NDVI/EVI/NDWI computation, band selection).\n",
    "4. For each patch and month, sample the earliest image's pixels and export as CSV into your Google Drive. Copy paste the code into your Google Earth Engine.\n"
   ],
   "id": "1c22ad8c6bf03dc8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "// ======================================================\n",
    "// GEE Script: Export One CSV Per 256x256 Patch Over an Adjusted Study Area (using lat/lon arithmetic)\n",
    "// ======================================================\n",
    "\n",
    "// ----- 1. Define the Original Study Area Polygon (in lat/lon) -----\n",
    "var origPolygon = ee.Geometry.Polygon([\n",
    "  [\n",
    "    [107.57481296526105, 33.62952626245739],\n",
    "    [107.67265995012433, 33.62952626245739],\n",
    "    [107.67265995012433, 33.786036563473694],\n",
    "    [107.57481296526105, 33.786036563473694],\n",
    "    [107.57481296526105, 33.62952626245739]\n",
    "  ]\n",
    "]);\n",
    "\n",
    "// Compute the centroid of the original polygon.\n",
    "var centroid = origPolygon.centroid();\n",
    "var centerCoords = centroid.coordinates();\n",
    "var centerLon = ee.Number(centerCoords.get(0));\n",
    "var centerLat = ee.Number(centerCoords.get(1));\n",
    "print(\"Centroid (lon, lat):\", centerLon, centerLat);\n",
    "\n",
    "// ----- 2. Define the New Study Area Using Approximate Meter-to-Degree Conversions -----\n",
    "// Desired new dimensions (in meters) to allow an integer number of 256×256 patches.\n",
    "// For 28 patches we choose: width = 10,240 m, height = 17,920 m.\n",
    "var desiredWidthMeters = 10240;\n",
    "var desiredHeightMeters = 17920;\n",
    "\n",
    "// Conversion factors at the centroid (approximate)\n",
    "var metersPerDegLat = 111320;  // roughly\n",
    "var cosLat = centerLat.multiply(Math.PI).divide(180).cos();\n",
    "var metersPerDegLon = ee.Number(111320).multiply(cosLat);\n",
    "\n",
    "// Compute new dimensions in degrees.\n",
    "var newWidthDeg = ee.Number(desiredWidthMeters).divide(metersPerDegLon);\n",
    "var newHeightDeg = ee.Number(desiredHeightMeters).divide(metersPerDegLat);\n",
    "print(\"New study area dimensions (degrees):\", newWidthDeg, \"x\", newHeightDeg);\n",
    "\n",
    "// Define the new study area (centered on the centroid).\n",
    "var halfWidthDeg = newWidthDeg.divide(2);\n",
    "var halfHeightDeg = newHeightDeg.divide(2);\n",
    "var newLonMin = centerLon.subtract(halfWidthDeg);\n",
    "var newLonMax = centerLon.add(halfWidthDeg);\n",
    "var newLatMin = centerLat.subtract(halfHeightDeg);\n",
    "var newLatMax = centerLat.add(halfHeightDeg);\n",
    "var newStudyArea = ee.Geometry.Rectangle([newLonMin, newLatMin, newLonMax, newLatMax]);\n",
    "Map.centerObject(newStudyArea, 10);\n",
    "Map.addLayer(newStudyArea, {color: 'red'}, 'Adjusted Study Area');\n",
    "\n",
    "// ----- 3. Generate a Grid of 256x256 Patches in Degrees -----\n",
    "// At 10 m resolution, a 256×256 patch covers 256*10 = 2560 m on a side.\n",
    "// Convert 2560 m to degrees using the same conversion factors.\n",
    "var patchWidthDeg = ee.Number(2560).divide(metersPerDegLon);\n",
    "var patchHeightDeg = ee.Number(2560).divide(metersPerDegLat);\n",
    "print(\"Patch size (degrees):\", patchWidthDeg, \"x\", patchHeightDeg);\n",
    "\n",
    "// Compute number of patches horizontally and vertically.\n",
    "var numCols = newWidthDeg.divide(patchWidthDeg).floor();\n",
    "var numRows = newHeightDeg.divide(patchHeightDeg).floor();\n",
    "print(\"Number of patches (cols x rows):\", numCols.getInfo(), \"x\", numRows.getInfo(),\n",
    "      \"=\", numCols.multiply(numRows).getInfo(), \"patches.\");\n",
    "\n",
    "// Create grid features.\n",
    "var gridFeatures = [];\n",
    "var nCols = numCols.getInfo();\n",
    "var nRows = numRows.getInfo();\n",
    "for (var i = 0; i < nCols; i++) {\n",
    "  for (var j = 0; j < nRows; j++) {\n",
    "    var lon0 = newLonMin.add(ee.Number(i).multiply(patchWidthDeg));\n",
    "    var lat0 = newLatMin.add(ee.Number(j).multiply(patchHeightDeg));\n",
    "    var lon1 = lon0.add(patchWidthDeg);\n",
    "    var lat1 = lat0.add(patchHeightDeg);\n",
    "    var patchGeom = ee.Geometry.Rectangle([lon0, lat0, lon1, lat1]);\n",
    "    var patchFeature = ee.Feature(patchGeom, { id: 'patch_' + i + '_' + j });\n",
    "    gridFeatures.push(patchFeature);\n",
    "  }\n",
    "}\n",
    "var gridFC = ee.FeatureCollection(gridFeatures);\n",
    "print(\"Total patches in grid:\", gridFC.size());\n",
    "Map.addLayer(gridFC, {color: 'blue'}, \"Grid Patches\");\n",
    "\n",
    "// ----- 4. Define Date Range and Sentinel-2 Image Collection -----\n",
    "var startDate = '2022-01-01';\n",
    "var endDate   = '2022-12-31';\n",
    "var s2Collection = ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\")\n",
    "  .filterDate(startDate, endDate)\n",
    "  .filterBounds(newStudyArea)\n",
    "  .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 20));\n",
    "\n",
    "// ----- 5. Define Functions for Image Processing (Without DEM) -----\n",
    "function maskClouds(image) {\n",
    "  var qa = image.select('QA60');\n",
    "  var cloudBitMask = 1 << 10;\n",
    "  var cirrusBitMask = 1 << 11;\n",
    "  var mask = qa.bitwiseAnd(cloudBitMask).eq(0)\n",
    "              .and(qa.bitwiseAnd(cirrusBitMask).eq(0));\n",
    "  return image.updateMask(mask);\n",
    "}\n",
    "\n",
    "function addIndices(image) {\n",
    "  var ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI');\n",
    "  var evi = image.expression(\n",
    "    '2.5 * ((NIR - RED) / (NIR + 6 * RED - 7.5 * BLUE + 1))',\n",
    "    {\n",
    "      'NIR': image.select('B8'),\n",
    "      'RED': image.select('B4'),\n",
    "      'BLUE': image.select('B2')\n",
    "    }\n",
    "  ).rename('EVI');\n",
    "  var ndwi = image.expression(\n",
    "    '(GREEN - NIR) / (GREEN + NIR)',\n",
    "    {\n",
    "      'GREEN': image.select('B3'),\n",
    "      'NIR': image.select('B8')\n",
    "    }\n",
    "  ).rename('NDWI');\n",
    "  return image.addBands([ndvi, evi, ndwi]);\n",
    "}\n",
    "\n",
    "function selectBands(image) {\n",
    "  var originalBands = ['B1','B2','B3','B4','B5','B6','B7','B8','B8A','B9','B11','B12','AOT','WVP'];\n",
    "  var rgbBands = ['TCI_R','TCI_G','TCI_B'];\n",
    "  var indexBands = ['NDVI','EVI','NDWI'];\n",
    "  return image.select(originalBands.concat(rgbBands).concat(indexBands));\n",
    "}\n",
    "\n",
    "var s2Processed = s2Collection\n",
    "  .map(maskClouds)\n",
    "  .map(addIndices)\n",
    "  .map(selectBands)\n",
    "  .map(function(img) { return img.unmask(-999); });\n",
    "\n",
    "// ----- 6. For Each Patch and Each Month, Sample Pixels -----\n",
    "// For each patch and for each month (1–12), select the earliest image and sample every pixel.\n",
    "var months = ee.List.sequence(1, 12);\n",
    "var patchList = gridFC.toList(gridFC.size());\n",
    "var numPatches = patchList.size().getInfo();\n",
    "print(\"Number of patches to process:\", numPatches);\n",
    "\n",
    "for (var i = 0; i < numPatches; i++) {\n",
    "  var patch = ee.Feature(patchList.get(i));\n",
    "  var patchId = patch.get('id');\n",
    "  print(\"Processing patch:\", patchId);\n",
    "\n",
    "  var monthlySamples = months.map(function(m) {\n",
    "    var monthlyImages = s2Processed\n",
    "      .filter(ee.Filter.calendarRange(m, m, 'month'))\n",
    "      .filterBounds(patch.geometry());\n",
    "    var sorted = monthlyImages.sort('system:time_start');\n",
    "    var firstImage = ee.Image(sorted.first());\n",
    "    var samples = ee.Algorithms.If(\n",
    "      sorted.size().gt(0),\n",
    "      firstImage.sample({\n",
    "        region: patch.geometry(),\n",
    "        scale: 10,\n",
    "        projection: 'EPSG:4326',\n",
    "        geometries: true\n",
    "      }).map(function(feat) {\n",
    "        return feat.set({\n",
    "          'image_date': firstImage.date().format('YYYY-MM-dd'),\n",
    "          'patch_id': patchId\n",
    "        });\n",
    "      }),\n",
    "      ee.FeatureCollection([])\n",
    "    );\n",
    "    return ee.FeatureCollection(samples);\n",
    "  });\n",
    "\n",
    "  var patchSamples = ee.FeatureCollection(monthlySamples).flatten();\n",
    "  print(\"Patch\", patchId, \"samples count:\", patchSamples.size());\n",
    "\n",
    "  Export.table.toDrive({\n",
    "    collection: patchSamples,\n",
    "    description: 'LarchCN_256x256_2022_monthly_' + patchId.getInfo(),\n",
    "    fileFormat: 'CSV',\n",
    "    folder: '2025-02-09_larch'\n",
    "  });\n",
    "}\n",
    "\n",
    "print(\"Script executed. Check the Tasks tab for exports.\");\n"
   ],
   "id": "e1e4d77fd2dd3749"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## (2) CSV summarizer, cleaner, checker\n",
    "\n",
    "When you get the CSVs, there is a .geo column. Run this code in order to use regex to extract lat long coordinates from .geo column. We also drop other unused columns in the process, and then summarize the CSV."
   ],
   "id": "6031158346b5630a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### GEE time series cleaner",
   "id": "4410eb994fd46235"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# CSV Cleaner Function (Do Not Modify)\n",
    "# -------------------------------------------------------------------\n",
    "def clean_csv(input_path):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(input_path)\n",
    "\n",
    "    # Extract latitude and longitude from .geo column using regex\n",
    "    def extract_coordinates(geo_str):\n",
    "        match = re.search(r'\\[([-+]?\\d*\\.\\d+),\\s*([-+]?\\d*\\.\\d+)\\]', geo_str)\n",
    "        if match:\n",
    "            return float(match.group(1)), float(match.group(2))\n",
    "        return None, None\n",
    "\n",
    "    df['longitude'], df['latitude'] = zip(*df['.geo'].apply(extract_coordinates))\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    df = df.drop(columns=['system:index', 'month', '.geo'])\n",
    "\n",
    "    # Ensure all feature columns are numeric\n",
    "    feature_cols = [\n",
    "        \"AOT\", \"B1\", \"B11\", \"B12\", \"B2\", \"B3\", \"B4\", \"B5\",\n",
    "        \"B6\", \"B7\", \"B8\", \"B8A\", \"B9\", \"EVI\", \"NDVI\", \"NDWI\",\n",
    "        \"TCI_B\", \"TCI_G\", \"TCI_R\", \"WVP\"\n",
    "    ]\n",
    "    for col in feature_cols:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "    # Handle missing values (forward fill)\n",
    "    df[feature_cols] = df[feature_cols].ffill()\n",
    "\n",
    "    # Save the cleaned CSV\n",
    "    output_path = os.path.splitext(input_path)[0] + \"_cleaned.csv\"\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"Cleaned CSV saved to: {output_path}\")\n",
    "    return output_path\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# CSV Summarizer Function\n",
    "# -------------------------------------------------------------------\n",
    "def analyze_csv(file_path):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Get column names and data types\n",
    "    column_info = df.dtypes.reset_index()\n",
    "    column_info.columns = [\"Column Name\", \"Data Type\"]\n",
    "\n",
    "    # Get dataset size\n",
    "    dataset_size = df.shape\n",
    "\n",
    "    # Display results\n",
    "    print(\"\\nCSV Summary:\")\n",
    "    print(\"Columns and Data Types:\")\n",
    "    print(column_info.to_string(index=False))\n",
    "    print(f\"\\nTotal Rows: {dataset_size[0]}\")\n",
    "    print(f\"Total Columns: {dataset_size[1]}\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Detect Non-Numeric Columns Function\n",
    "# -------------------------------------------------------------------\n",
    "def detect_non_numeric_columns(csv_file):\n",
    "    \"\"\"\n",
    "    Reads csv_file and checks each column for non-numeric values.\n",
    "    Returns a dictionary mapping column names to the number of entries that become NaN\n",
    "    after converting to numeric (i.e. problematic entries).\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_file, engine='python', on_bad_lines='skip', quoting=csv.QUOTE_NONE)\n",
    "    non_numeric = {}\n",
    "    for col in df.columns:\n",
    "        try:\n",
    "            converted = pd.to_numeric(df[col], errors='coerce')\n",
    "            additional_nans = converted.isna() & ~df[col].isna()\n",
    "            count = additional_nans.sum()\n",
    "            if count > 0:\n",
    "                non_numeric[col] = count\n",
    "        except Exception as e:\n",
    "            non_numeric[col] = str(e)\n",
    "    return non_numeric\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Check for -999 Values Function\n",
    "# -------------------------------------------------------------------\n",
    "def check_minus999_values(csv_file):\n",
    "    \"\"\"\n",
    "    Checks for occurrences of -999 in the dataset.\n",
    "    Returns a dictionary mapping column names to the count of -999 values.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_file, engine='python', on_bad_lines='skip', quoting=csv.QUOTE_NONE)\n",
    "    minus999_counts = {}\n",
    "    for col in df.columns:\n",
    "        try:\n",
    "            numeric_series = pd.to_numeric(df[col], errors='coerce')\n",
    "            count_minus999 = (numeric_series == -999).sum()\n",
    "            if count_minus999 > 0:\n",
    "                minus999_counts[col] = count_minus999\n",
    "        except Exception as e:\n",
    "            minus999_counts[col] = f\"Error: {e}\"\n",
    "    return minus999_counts\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Main Processing: Clean, Summarize, and Check CSV Files\n",
    "# -------------------------------------------------------------------\n",
    "def main():\n",
    "    folder_path = r\"C:\\Users\\jmm267\\Downloads\\Binbin\\Dataset\\GEE_unseen_cleaned_time_series\"  # Update if necessary.\n",
    "    csv_files = glob.glob(os.path.join(folder_path, \"*.csv\"))\n",
    "    print(f\"Found {len(csv_files)} CSV files in {folder_path}\")\n",
    "\n",
    "    for csv_file in tqdm(csv_files, desc=\"Processing CSV files\"):\n",
    "        # Clean the CSV if not already cleaned\n",
    "        if not csv_file.endswith(\"_cleaned.csv\"):\n",
    "            cleaned_path = clean_csv(csv_file)\n",
    "        else:\n",
    "            cleaned_path = csv_file\n",
    "\n",
    "        print(f\"\\n--- Summary for: {cleaned_path} ---\")\n",
    "        analyze_csv(cleaned_path)\n",
    "\n",
    "        print(\"\\nChecking for non-numeric columns:\")\n",
    "        problems = detect_non_numeric_columns(cleaned_path)\n",
    "        if problems:\n",
    "            for col, count in problems.items():\n",
    "                print(f\"  {col}: {count} problematic entries\")\n",
    "        else:\n",
    "            print(\"  All columns are numeric (or properly handled).\")\n",
    "\n",
    "        print(\"\\nChecking for -999 values:\")\n",
    "        minus999_problems = check_minus999_values(cleaned_path)\n",
    "        if minus999_problems:\n",
    "            for col, count in minus999_problems.items():\n",
    "                print(f\"  {col}: {count} occurrences of -999\")\n",
    "        else:\n",
    "            print(\"  No -999 values found.\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ],
   "id": "ff40ee88f916174e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## (3) LSTM (long short term memory)\n",
    "\n",
    "Run this code after cleaning the data. LSTM  is a type of RNN (recurrent neural network) that's best for time series data because it can \"learn\" the trends between times properly.\n",
    "\n",
    "check for CUDA and tensorflow."
   ],
   "id": "e8978442adb92bc8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T11:23:16.678730Z",
     "start_time": "2025-02-19T11:23:16.674427Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## CHECK FOR CUDA AND TENSORFLOW\n",
    "\n",
    "print(f\"TensorFlow Version: {tf.__version__}\")\n",
    "import torch\n",
    "print(\"Number of GPU: \", torch.cuda.device_count())\n",
    "print(\"GPU Name: \", torch.cuda.get_device_name())\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ],
   "id": "e513ea3cd7eb7259",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.18.0\n",
      "Number of GPU:  1\n",
      "GPU Name:  NVIDIA RTX 2000 Ada Generation\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## LSTM IMPLEMNETATION\n",
    "## EXPORT WEIGHTS IN .PTH FORMAT \"lstm_classifier.pth\"\n",
    "## RENAME GROUNDTRUTH CSV FILEPATH AT MAIN\n",
    "\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "if device.type == 'cuda':\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name())\n",
    "\n",
    "##############################################################################\n",
    "# 1) Dataset Class for 12-Month Sequences\n",
    "##############################################################################\n",
    "class GroundtruthTimeSeriesDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Reads a CSV with repeated rows over months for each (lat, lon),\n",
    "    e.g. 12 rows for 12 months. We group them to form a single time-series\n",
    "    sample: shape (12, number_of_features). The 'Class' label is taken\n",
    "    from the first row's 'Class' (assuming each lat/lon is a single species).\n",
    "\n",
    "    If a lat/lon has fewer than 12 months, we can pad with the last row.\n",
    "    If it has more than 12, we can slice down to 12.\n",
    "\n",
    "    The user can define which columns are the 'feature_cols'.\n",
    "    We'll store 'label_encoder' for Class strings -> integers.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, csv_path, feature_cols=None, desired_length=12):\n",
    "        print(f\"Reading CSV file: {csv_path}\")\n",
    "        df = pd.read_csv(csv_path, parse_dates=['image_date'])\n",
    "\n",
    "        if feature_cols is None:\n",
    "            # You indicated at least 20 features: AOT..WVP, EVI, NDVI, NDWI, etc.\n",
    "            # Adjust to exactly the ones you want. Example below:\n",
    "            self.feature_cols = [\n",
    "                \"AOT\",\"B1\",\"B11\",\"B12\",\"B2\",\"B3\",\"B4\",\"B5\",\n",
    "                \"B6\",\"B7\",\"B8\",\"B8A\",\"B9\",\"EVI\",\"NDVI\",\"NDWI\",\n",
    "                \"TCI_B\",\"TCI_G\",\"TCI_R\",\"WVP\"\n",
    "            ]\n",
    "        else:\n",
    "            self.feature_cols = feature_cols\n",
    "\n",
    "        # We'll group by (latitude, longitude). If you prefer rounding, do so here.\n",
    "        # e.g. df['lat_lon_id'] = ...\n",
    "        # But let's assume the lat/lon values are consistent for each patch.\n",
    "        df[\"lat_lon_id\"] = df[\"latitude\"].astype(str) + \"_\" + df[\"longitude\"].astype(str)\n",
    "\n",
    "        # Encode \"Class\" if present\n",
    "        if \"Class\" not in df.columns:\n",
    "            raise ValueError(\"CSV must have 'Class' column for supervised training.\")\n",
    "\n",
    "        # Build label encoder\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        class_strs = df[\"Class\"].unique()\n",
    "        self.label_encoder.fit(class_strs)\n",
    "\n",
    "        self.desired_length = desired_length\n",
    "        self.samples = []  # each is a (time_series_tensor, label_int)\n",
    "\n",
    "        # group by lat_lon_id\n",
    "        grouped = df.groupby(\"lat_lon_id\", sort=False)\n",
    "        for group_id, group_data in grouped:\n",
    "            group_data = group_data.sort_values(\"image_date\")\n",
    "            arr = group_data[self.feature_cols].to_numpy(dtype=float)  # shape (T, D)\n",
    "            T, D = arr.shape\n",
    "\n",
    "            if T < desired_length:\n",
    "                # pad with last row\n",
    "                pad = np.tile(arr[-1:], (desired_length - T, 1))\n",
    "                arr = np.vstack([arr, pad])\n",
    "            elif T > desired_length:\n",
    "                arr = arr[:desired_length]\n",
    "\n",
    "            # Convert to torch tensor\n",
    "            seq_tensor = torch.tensor(arr, dtype=torch.float)  # shape (12, #features)\n",
    "            # Label: from the first row's 'Class'\n",
    "            class_str = group_data.iloc[0][\"Class\"]\n",
    "            label_id = self.label_encoder.transform([class_str])[0]\n",
    "\n",
    "            self.samples.append((seq_tensor, label_id))\n",
    "\n",
    "        print(f\"Constructed {len(self.samples)} time-series samples from {csv_path}.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq, label = self.samples[idx]\n",
    "        return seq, label\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# 2) Neural Network Model: LSTM (or GRU) to handle 12×D sequences\n",
    "##############################################################################\n",
    "class LSTMClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    An LSTM-based classifier that:\n",
    "      - Reads sequences of shape (T=12, D=20+).\n",
    "      - Optionally: you can add multiple LSTM layers, dropout, etc.\n",
    "      - Then we take the final hidden state or last time step for classification.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, num_classes, drop_prob=0.2):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # You can also use nn.GRU(...) if you prefer a GRU\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=drop_prob,\n",
    "            bidirectional=False\n",
    "        )\n",
    "        # final classification layer\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: shape (B, T, D)\n",
    "        # Initialize hidden + cell states:\n",
    "        batch_size = x.size(0)\n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(x.device)\n",
    "\n",
    "        # LSTM forward\n",
    "        out, (hn, cn) = self.lstm(x, (h0, c0))\n",
    "        # out shape: (B, T, hidden_dim)\n",
    "        # hn shape: (num_layers, B, hidden_dim) => final hidden state for last time step\n",
    "\n",
    "        # We'll take the last time step's output\n",
    "        # or we can just use hn[-1], which is the last layer's hidden state\n",
    "        last_out = out[:, -1, :]  # shape (B, hidden_dim)\n",
    "        logits = self.fc(last_out)  # shape (B, num_classes)\n",
    "        return logits\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# 3) Main Training Pipeline\n",
    "##############################################################################\n",
    "def train_lstm_classifier(\n",
    "    csv_path,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    hidden_dim=128,\n",
    "    num_layers=1,\n",
    "    drop_prob=0.2,\n",
    "    save_path=\"lstm_classifier.pth\"\n",
    "):\n",
    "    # 1) Create Dataset\n",
    "    dataset = GroundtruthTimeSeriesDataset(csv_path)\n",
    "\n",
    "    # 2) Train/Val Split\n",
    "    ds_len = len(dataset)\n",
    "    train_size = int(0.8 * ds_len)\n",
    "    val_size = ds_len - train_size\n",
    "    train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    num_classes = len(dataset.label_encoder.classes_)\n",
    "    input_dim = len(dataset.feature_cols)\n",
    "\n",
    "    print(f\"Dataset has {ds_len} time-series samples, {num_classes} distinct classes.\")\n",
    "    print(f\"Using LSTM with input_dim={input_dim}, hidden_dim={hidden_dim}, num_classes={num_classes}.\")\n",
    "    print(f\"Training for {epochs} epochs...\")\n",
    "\n",
    "    # 3) Build Model\n",
    "    model = LSTMClassifier(\n",
    "        input_dim=input_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_layers=num_layers,\n",
    "        num_classes=num_classes,\n",
    "        drop_prob=drop_prob\n",
    "    ).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    # 4) Training Loop\n",
    "    for epoch in range(1, epochs+1):\n",
    "        # ---- train ----\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        correct, total = 0, 0\n",
    "        for X, y in tqdm(train_loader, desc=f\"Epoch {epoch}/{epochs} (train)\", leave=False):\n",
    "            X = X.to(device)            # shape (B, 12, input_dim)\n",
    "            y = y.to(device)            # shape (B,)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(X)           # shape (B, num_classes)\n",
    "            loss = criterion(logits, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item() * X.size(0)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += X.size(0)\n",
    "        train_acc = correct / total\n",
    "        avg_loss = total_loss / total\n",
    "\n",
    "        # ---- validate ----\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct, val_total = 0, 0\n",
    "        all_val_preds = []\n",
    "        all_val_labels = []\n",
    "        with torch.no_grad():\n",
    "            for Xv, yv in tqdm(val_loader, desc=f\"Epoch {epoch}/{epochs} (val)\", leave=False):\n",
    "                Xv = Xv.to(device)\n",
    "                yv = yv.to(device)\n",
    "                logits_v = model(Xv)\n",
    "                loss_v = criterion(logits_v, yv)\n",
    "                val_loss += loss_v.item() * Xv.size(0)\n",
    "                preds_v = torch.argmax(logits_v, dim=1)\n",
    "                val_correct += (preds_v == yv).sum().item()\n",
    "                val_total += Xv.size(0)\n",
    "                all_val_preds.extend(preds_v.cpu().numpy())\n",
    "                all_val_labels.extend(yv.cpu().numpy())\n",
    "\n",
    "        val_acc = val_correct / val_total\n",
    "        avg_val_loss = val_loss / val_total\n",
    "        print(f\"[Epoch {epoch}/{epochs}] Train Loss={avg_loss:.4f}, Train Acc={train_acc:.2f}, \"\n",
    "              f\"Val Loss={avg_val_loss:.4f}, Val Acc={val_acc:.2f}\")\n",
    "\n",
    "    # 5) Save the model\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"\\nModel saved to {save_path}.\")\n",
    "\n",
    "    # 6) Final Confusion Matrix on val set\n",
    "    cm = confusion_matrix(all_val_labels, all_val_preds)\n",
    "    print(\"\\nConfusion Matrix (on validation set):\")\n",
    "    print(cm)\n",
    "\n",
    "    # Classification Report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    # Convert numeric labels back to strings\n",
    "    inv_class_map = {i: c for i, c in enumerate(dataset.label_encoder.classes_)}\n",
    "    all_val_preds_str = [inv_class_map[p] for p in all_val_preds]\n",
    "    all_val_labels_str = [inv_class_map[l] for l in all_val_labels]\n",
    "    print(classification_report(all_val_labels_str, all_val_preds_str))\n",
    "\n",
    "    return model, dataset\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# 4) Example Usage\n",
    "##############################################################################\n",
    "if __name__ == \"__main__\":\n",
    "    groundtruth_csv = r\"C:\\Users\\jmm267\\Downloads\\Binbin\\Dataset\\groundtruth_raw\\time_series_cleaned\\groundtruth_cleaned_final.csv\"\n",
    "    model, ds = train_lstm_classifier(\n",
    "        csv_path=groundtruth_csv,\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        hidden_dim=128,\n",
    "        num_layers=2,\n",
    "        drop_prob=0.2,\n",
    "        save_path=\"lstm_classifier_model.pth\"\n",
    "    )\n"
   ],
   "id": "4fd0545b1a69a11a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "###  After training 100 epochs on the groundtruth file, we can access the .pth file and its weights to perform classification on unseen data.",
   "id": "645b01e807084908"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "## Classifier code starts here ##\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 0. Check CUDA / GPU availability\n",
    "# ---------------------------------------------------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"=== Checking for GPU (CUDA) availability ===\")\n",
    "if device.type == 'cuda':\n",
    "    print(f\"GPU is available! Using device: {device}\")\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name()}\")\n",
    "else:\n",
    "    print(\"No GPU found. Running on CPU.\")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 1. LSTM Model Architecture\n",
    "# ---------------------------------------------------------------------\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, num_classes, drop_prob=0.2):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=drop_prob,\n",
    "            bidirectional=False\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        # Initialize hidden/cell\n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(x.device)\n",
    "\n",
    "        out, (hn, cn) = self.lstm(x, (h0, c0))\n",
    "        # last time-step output\n",
    "        last_out = out[:, -1, :]  # shape (B, hidden_dim)\n",
    "        logits = self.fc(last_out)\n",
    "        return logits\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 2. BlindPatchDataset for unlabeled CSV\n",
    "# ---------------------------------------------------------------------\n",
    "class BlindPatchDataset(Dataset):\n",
    "    \"\"\"\n",
    "    For a single CSV with columns:\n",
    "      [AOT,B1,B11,B12,B2,B3,B4,B5,B6,B7,B8,B8A,B9,EVI,NDVI,NDWI,\n",
    "       TCI_B,TCI_G,TCI_R,WVP, image_date,longitude,latitude]\n",
    "    We group by lat/lon, sort by image_date, ensure T=12 (pad or truncate).\n",
    "    Returns (seq_tensor, (lat, lon)) for each pixel/time-series.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, csv_path, feature_cols=None, desired_length=12):\n",
    "        print(f\"\\n--- Reading CSV file: {csv_path}\")\n",
    "        self.df = pd.read_csv(csv_path, parse_dates=[\"image_date\"])\n",
    "        print(f\"[DEBUG] Shape of read DataFrame: {self.df.shape}\")\n",
    "\n",
    "        if feature_cols is None:\n",
    "            self.feature_cols = [\n",
    "                \"AOT\",\"B1\",\"B11\",\"B12\",\"B2\",\"B3\",\"B4\",\"B5\",\n",
    "                \"B6\",\"B7\",\"B8\",\"B8A\",\"B9\",\"EVI\",\"NDVI\",\"NDWI\",\n",
    "                \"TCI_B\",\"TCI_G\",\"TCI_R\",\"WVP\"\n",
    "            ]\n",
    "        else:\n",
    "            self.feature_cols = feature_cols\n",
    "\n",
    "        # Combine lat/lon into a group id\n",
    "        self.df[\"lat_lon_id\"] = (\n",
    "            self.df[\"latitude\"].round(6).astype(str)\n",
    "            + \"_\"\n",
    "            + self.df[\"longitude\"].round(6).astype(str)\n",
    "        )\n",
    "\n",
    "        self.desired_length = desired_length\n",
    "        self.samples = []\n",
    "        self.latlons = []\n",
    "\n",
    "        grouped = self.df.groupby(\"lat_lon_id\", sort=False)\n",
    "        for group_id, gdata in grouped:\n",
    "            gdata_sorted = gdata.sort_values(\"image_date\")\n",
    "            arr = gdata_sorted[self.feature_cols].to_numpy(dtype=float)  # shape (T, D)\n",
    "            T, D = arr.shape\n",
    "\n",
    "            if T < desired_length:\n",
    "                # pad with last row\n",
    "                pad = np.tile(arr[-1:], (desired_length - T, 1))\n",
    "                arr = np.vstack([arr, pad])\n",
    "            elif T > desired_length:\n",
    "                arr = arr[:desired_length]\n",
    "\n",
    "            seq_tensor = torch.tensor(arr, dtype=torch.float)\n",
    "            lat0 = gdata_sorted.iloc[0][\"latitude\"]\n",
    "            lon0 = gdata_sorted.iloc[0][\"longitude\"]\n",
    "            self.samples.append(seq_tensor)\n",
    "            self.latlons.append((lat0, lon0))\n",
    "\n",
    "        print(f\"[DEBUG] Constructed {len(self.samples)} time-series samples.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx], self.latlons[idx]\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 2.5 Custom Collate Function\n",
    "# ---------------------------------------------------------------------\n",
    "def collate_blind_patches(batch):\n",
    "    \"\"\"\n",
    "    Expects a list of (seq_tensor, (lat, lon)) pairs.\n",
    "    We'll stack all seq_tensors into (B, T, D),\n",
    "    and keep coords as a list of (lat, lon).\n",
    "    \"\"\"\n",
    "    seqs = []\n",
    "    coords = []\n",
    "    for (seq_tensor, (lat, lon)) in batch:\n",
    "        seqs.append(seq_tensor)\n",
    "        coords.append((lat, lon))\n",
    "\n",
    "    # Stack the sequence tensors along the batch dimension\n",
    "    seq_batch = torch.stack(seqs, dim=0)  # shape (B, 12, feature_dim)\n",
    "\n",
    "    return seq_batch, coords\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 3. Inference Function\n",
    "# ---------------------------------------------------------------------\n",
    "def infer_on_blind_data(\n",
    "    folder_path,                   # path to raw_cleaned folder\n",
    "    model_path=\"lstm_classifier_model.pth\",\n",
    "    output_folder=\"inference_results\",\n",
    "    batch_size=32,\n",
    "    hidden_dim=128,\n",
    "    num_layers=2,\n",
    "    drop_prob=0.2,\n",
    "    feature_cols=None\n",
    "):\n",
    "    \"\"\"\n",
    "    - folder_path: Directory that contains *cleaned.csv files\n",
    "    - model_path: Path to .pth model weights\n",
    "    - output_folder: Where we store the results\n",
    "    - batch_size, hidden_dim, num_layers, drop_prob: must match your training config\n",
    "    - feature_cols: same features used in training\n",
    "    \"\"\"\n",
    "    print(\"\\n=== Starting Inference on Blind Data ===\")\n",
    "    csv_files = glob.glob(os.path.join(folder_path, \"*cleaned.csv\"))\n",
    "    print(f\"Found {len(csv_files)} files in {folder_path} that match '*cleaned.csv'\")\n",
    "\n",
    "    print(f\"Model path: {model_path}\")\n",
    "    print(f\"Output folder: {output_folder}\")\n",
    "    print(\"Feature cols:\", feature_cols)\n",
    "    print(\"--------------------------------------------------\")\n",
    "\n",
    "    # Suppose you have 5 classes from training\n",
    "    num_classes = 5\n",
    "    input_dim = len(feature_cols) if feature_cols else 20\n",
    "\n",
    "    # Rebuild the same LSTM\n",
    "    print(f\"[INFO] Building LSTM model: input_dim={input_dim}, hidden_dim={hidden_dim}, num_classes={num_classes}\")\n",
    "    model = LSTMClassifier(\n",
    "        input_dim=input_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_layers=num_layers,\n",
    "        num_classes=num_classes,\n",
    "        drop_prob=drop_prob\n",
    "    )\n",
    "    print(f\"[INFO] Loading state_dict from: {model_path}\")\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Label mapping from training\n",
    "    label_mapping = [\"deci_broad\", \"ever_coni\", \"larch_CN\", \"larch_JP\", \"shrubland\"]\n",
    "\n",
    "    # Ensure output folder\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    for csv_path in tqdm(csv_files, desc=\"CSV Files\", unit=\"file\"):\n",
    "        print(f\"\\n--- Inference on file: {csv_path}\")\n",
    "        try:\n",
    "            ds = BlindPatchDataset(csv_path, feature_cols=feature_cols)\n",
    "            # Pass our custom collate function:\n",
    "            dl = DataLoader(ds, batch_size=batch_size, shuffle=False, collate_fn=collate_blind_patches)\n",
    "\n",
    "            print(f\"[DEBUG] Dataset has {len(ds)} samples. Beginning inference...\")\n",
    "\n",
    "            all_preds = []\n",
    "            all_coords = []\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for seq_batch, coords_batch in tqdm(dl, desc=\"Predicting Batches\", leave=False):\n",
    "                    # seq_batch: shape (B, 12, input_dim)\n",
    "                    # coords_batch: list of length B, each is (lat, lon)\n",
    "                    seq_batch = seq_batch.to(device)\n",
    "                    logits = model(seq_batch)\n",
    "                    preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "                    all_preds.extend(preds)\n",
    "                    all_coords.extend(coords_batch)\n",
    "\n",
    "            if len(all_preds) != len(all_coords):\n",
    "                raise ValueError(f\"[ERROR] length mismatch: preds={len(all_preds)}, coords={len(all_coords)}\")\n",
    "\n",
    "            pred_classes = [label_mapping[p] for p in all_preds]\n",
    "\n",
    "            # Build results DataFrame\n",
    "            print(f\"[DEBUG] Building DataFrame for {len(pred_classes)} predictions...\")\n",
    "            results_df = pd.DataFrame({\n",
    "                \"latitude\": [c[0] for c in all_coords],\n",
    "                \"longitude\": [c[1] for c in all_coords],\n",
    "                \"predicted_class\": pred_classes\n",
    "            })\n",
    "            print(results_df.head(5))\n",
    "\n",
    "            base_name = os.path.splitext(os.path.basename(csv_path))[0]\n",
    "            out_csv = os.path.join(output_folder, base_name + \"_with_predictions.csv\")\n",
    "            results_df.to_csv(out_csv, index=False)\n",
    "            print(f\"Results saved to: {out_csv}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Failed on file {csv_path}\\nReason: {e}\")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 4. Example usage\n",
    "# ---------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    folder_path = r\"C:\\Users\\jmm267\\Downloads\\Binbin\\Dataset\\raw_cleaned\"\n",
    "    ## runs classification on all csv files in this directory\n",
    "    features_used = [\n",
    "        \"AOT\",\"B1\",\"B11\",\"B12\",\"B2\",\"B3\",\"B4\",\"B5\",\n",
    "        \"B6\",\"B7\",\"B8\",\"B8A\",\"B9\",\"EVI\",\"NDVI\",\"NDWI\",\n",
    "        \"TCI_B\",\"TCI_G\",\"TCI_R\",\"WVP\"\n",
    "    ]\n",
    "    ## indicate which features to use\n",
    "\n",
    "    ## call the main function here\n",
    "    infer_on_blind_data(\n",
    "        folder_path=folder_path,\n",
    "        model_path=\"lstm_classifier_model.pth\",\n",
    "        ##update the trained model path\n",
    "        output_folder=\"larchCN_inference_results\",\n",
    "        ##output the classified data into this folder\n",
    "        batch_size=32,\n",
    "        hidden_dim=128,\n",
    "        num_layers=2,\n",
    "        drop_prob=0.2,\n",
    "        feature_cols=features_used\n",
    "    )\n"
   ],
   "id": "339ee2a88636f24d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "605d2456e788f069"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
